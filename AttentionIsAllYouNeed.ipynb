{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c89d8d01-e9ed-4d11-93c4-b1c20b09e35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 15:28:53.333361: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-01 15:28:53.427916: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-01 15:28:53.834618: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-01 15:28:53.834684: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-01 15:28:53.834690: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2022-12-01 15:28:54.482128: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:05:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-12-01 15:28:54.511293: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-12-01 15:28:54.511319: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f093b71-30a2-4b68-8aef-94a862d9bb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_en = spacy.load(\"en_core_web_sm\")\n",
    "spacy_de = spacy.load(\"nl_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3676565f-edbf-4db1-a632-5ee8177ec9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index0:I\n",
      "index1:am\n",
      "index2:a\n",
      "index3:student\n"
     ]
    }
   ],
   "source": [
    "tokenized=spacy_en.tokenizer('I am a student')\n",
    "for i, token in enumerate(tokenized):\n",
    "    print(f'index{i}:{token.text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1baab936-51e0-4e1b-9cba-e56700983cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_de(text):\n",
    "    return [token.text for token in spacy_de.tokenizer(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [token.text for token in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb791992-5398-411c-9e26-954997bd97f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.legacy.data import Field, TabularDataset, BucketIterator, Iterator #torch==1.8.0 torchtext==0.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4db5fbb8-5a6a-4e68-bef9-a43857cbbf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = Field(tokenize=tokenize_de, init_token=\"<sos>\", eos_token=\"<eos>\", lower=True, batch_first=True)\n",
    "TRG = Field(tokenize=tokenize_en, init_token=\"<sos>\", eos_token=\"<eos>\", lower=True, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e37f79f-bfe3-48d3-a305-4063ebda1e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading training.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training.tar.gz: 100%|██████████████████████████████████████████████████████████████| 1.21M/1.21M [00:02<00:00, 488kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading validation.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation.tar.gz: 100%|███████████████████████████████████████████████████████████| 46.3k/46.3k [00:00<00:00, 85.0kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading mmt_task1_test2016.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mmt_task1_test2016.tar.gz: 100%|████████████████████████████████████████████████████| 66.2k/66.2k [00:00<00:00, 120kB/s]\n"
     ]
    }
   ],
   "source": [
    "from torchtext.legacy.datasets import Multi30k\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset = Multi30k.splits(exts=(\".de\", \".en\"), fields=(SRC, TRG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f00ff8d-8ed8-42d9-8319-b38cb0447ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터셋(training dataset) 크기: 29000개\n",
      "평가 데이터셋(validation dataset) 크기: 1014개\n",
      "테스트 데이터셋(testing dataset) 크기: 1000개\n"
     ]
    }
   ],
   "source": [
    "print(f\"학습 데이터셋(training dataset) 크기: {len(train_dataset.examples)}개\")\n",
    "print(f\"평가 데이터셋(validation dataset) 크기: {len(valid_dataset.examples)}개\")\n",
    "print(f\"테스트 데이터셋(testing dataset) 크기: {len(test_dataset.examples)}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7bb7e24e-083f-4b52-b88b-f4a8966a5ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ein', 'mann', ',', 'der', 'mit', 'einer', 'tasse', 'kaffee', 'an', 'einem', 'urinal', 'steht', '.']\n",
      "['a', 'man', 'standing', 'at', 'a', 'urinal', 'with', 'a', 'coffee', 'cup', '.']\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_dataset.examples[30])['src'])\n",
    "print(vars(train_dataset.examples[30])['trg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90d21765-e3aa-4931-9ab0-fa800aaa48c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(SRC): 7853\n",
      "len(TRG): 5893\n"
     ]
    }
   ],
   "source": [
    "#To get the initial input dimension\n",
    "SRC.build_vocab(train_dataset, min_freq=2) #select the words appear at least more than 2 \n",
    "TRG.build_vocab(train_dataset, min_freq=2)\n",
    "\n",
    "print(f\"len(SRC): {len(SRC.vocab)}\")\n",
    "print(f\"len(TRG): {len(TRG.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "192985af-9392-4dbe-bc11-acc545c495a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4112\n",
      "1752\n"
     ]
    }
   ],
   "source": [
    "print(TRG.vocab.stoi[\"abcabc\"]) # 없는 단어: 0 #with stoi, it can check inside \n",
    "print(TRG.vocab.stoi[TRG.pad_token]) # 패딩(padding): 1\n",
    "print(TRG.vocab.stoi[\"<sos>\"]) # : 2\n",
    "print(TRG.vocab.stoi[\"<eos>\"]) # : 3\n",
    "print(TRG.vocab.stoi[\"hello\"])\n",
    "print(TRG.vocab.stoi[\"world\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67d5291a-8d5d-4079-bd1f-b15923cdc0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "BATCH_SIZE=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67371e83-c397-4027-b409-008ec750b7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BucketIterator : The words contained in one sentence must be entered in order. \n",
    "# So it's good to make the number of words in a single batch have similar numbers.\n",
    "# Input as little padding in sort sentences as possible --> reduce the input dimension\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "train_iterator, valid_iterator, test_iterator=BucketIterator.splits(\n",
    "    (train_dataset, valid_dataset, test_dataset), batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7f966a6-223a-4404-874b-57fbd28ec86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫 번째 배치 크기: torch.Size([128, 27])\n",
      "인덱스 0: 2\n",
      "인덱스 1: 8\n",
      "인덱스 2: 16\n",
      "인덱스 3: 181\n",
      "인덱스 4: 12\n",
      "인덱스 5: 5\n",
      "인덱스 6: 1290\n",
      "인덱스 7: 126\n",
      "인덱스 8: 14\n",
      "인덱스 9: 0\n",
      "인덱스 10: 4\n",
      "인덱스 11: 3\n",
      "인덱스 12: 1\n",
      "인덱스 13: 1\n",
      "인덱스 14: 1\n",
      "인덱스 15: 1\n",
      "인덱스 16: 1\n",
      "인덱스 17: 1\n",
      "인덱스 18: 1\n",
      "인덱스 19: 1\n",
      "인덱스 20: 1\n",
      "인덱스 21: 1\n",
      "인덱스 22: 1\n",
      "인덱스 23: 1\n",
      "인덱스 24: 1\n",
      "인덱스 25: 1\n",
      "인덱스 26: 1\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(train_iterator):\n",
    "    src=batch.src\n",
    "    trg=batch.trg\n",
    "    \n",
    "    print(f\"첫 번째 배치 크기: {src.shape}\")\n",
    "    \n",
    "    #output of one sentence in the current batch\n",
    "    for i in range(src.shape[1]): #src.shape[1] : sequence length\n",
    "        print(f\"인덱스 {i}: {src[0][i].item()}\") #first sentence\n",
    "    break \n",
    "    #2 is <sos>, 3 is <eos>, the data between them represent each words, 1 is meaningless tocken(padding tocken, after 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bd96ed8a-bf0e-4ecd-bd81-4a16a7899f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "86126773-40a5-42e5-9b8a-a343fbaccbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim, n_heads, dropout_ratio):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert hidden_dim%n_heads==0\n",
    "        \n",
    "        self.hidden_dim=hidden_dim # embedding dimension of one word\n",
    "        self.n_heads=n_heads # number of each attention\n",
    "        self.head_dim=hidden_dim % n_heads\n",
    "        \n",
    "        self.fc_q=nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc_k=nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc_v=nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc_o=nn.Linear(hidden_dim, hidden_dim) #output linear\n",
    "        self.dropout=nn.Dropout(dropout_ratio)\n",
    "        self.scale=torch.sqrt(torch.FloatTensor([self.head_dim]))\n",
    "        \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        batch_size=query.shape[0]\n",
    "        \n",
    "        Q=self.fc_q(query)\n",
    "        K=self.fc_k(query)\n",
    "        V=self.fc_v(query)\n",
    "        \n",
    "        Q=Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3) #reshape\n",
    "        K=K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        V=V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        \n",
    "        energy=torch.matmul(Q, K.permute(0,1,3,2))/self.scale #Q * K and divide by scale in each heads\n",
    "        \n",
    "        if mast is not None:\n",
    "            energy=energy.masked_fill(mask==0, -1e9) #fill with -1e9 if mask is 0\n",
    "        \n",
    "        attention=torch.softmax(energy, dim=-1)\n",
    "        \n",
    "        #scaled dot product attention\n",
    "        x=torch.matmul(self.dropout(attention),V)\n",
    "        \n",
    "        x=x.permute(0,2,1,3).contiguous()\n",
    "        \n",
    "        x=x.view(batch_size, -1, self.hidden_dim) #concat\n",
    "        \n",
    "        x=self.fc_o(x) \n",
    "        \n",
    "        return x, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "637d3731-e3e8-418a-a3e7-37a9deeeff30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedforwardLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim, pf_dim, dropout_ratio):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc_1=nn.Linear(hidden_dim, pf_dim)\n",
    "        self.fc_2=nn.Linear(pf_dim, hidden_dim)\n",
    "        self.dropout=nn.Dropout(dropout_ratio)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=self.dropout(torch.relu(self.fc_1(x)))\n",
    "        x=self.fc_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9e7df0-716e-4e87-bf29-cecc3a32083d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim, n_heads, pf_dim, dropout_ratio):\n",
    "        super().__init__()\n",
    "        self.self_attn_layer_norm=nn.LayerNorm(hidden_dim)\n",
    "        self.ff_layer_norm=nn.LayerNorm(hidden_dim)\n",
    "        self.self_attention=MultiHeadAttentionLayer(hidden_dim, n_heads, dropout_ratio)\n",
    "        self.positionwise_feedforward=PositionwiseFeedforwardLayer(hidden_dim, pf_dim, dropout_ratio)\n",
    "        self.dropout=nn.Dropout(dropout_ratio)\n",
    "        \n",
    "    def forward(self, src, src_mask):\n",
    "        _src, _=self.self_attention(src, src, src, src_mask) #Q,K,V\n",
    "        src=self.self_attn_layer_norm(src+self.dropout(_src)) #residual connection and then apply to layer normalization\n",
    "        _src=self.positionwise_feedforward(src) #through feedforward\n",
    "        src=self.ff_layer_norm(src+self.dropout(_src)) #one more residual connection and then apply to layer normalization\n",
    "        return src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4e4464bc-236e-47e9-90b9-43c660173354",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, n_layers, n_heads, pf_dim, dropout_ratio, max_length=100):\n",
    "        super().__init__()\n",
    "        self.tok_embedding=nn.Embedding(input_dim, hidden_dim)\n",
    "        self.pos_embedding=nn.Embedding(max_langth, hidden_dim)\n",
    "        \n",
    "        self.layers=nn.ModuleList([EncoderLayer(hidden_dim, n_heads, pf_dim, dropout_ratio) for _ in range(n_layers)])\n",
    "        self.dropout=nn.Dropout(dropout_ratio)\n",
    "        self.scale=torch.sqrt(torch.FloatTensor([hidden_dim]))\n",
    "        \n",
    "    def forward(self, src, src_mask):\n",
    "        batch_size=src.shape[0]\n",
    "        src_len=src.shape[1]\n",
    "        \n",
    "        pos=torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1) #add one dimension\n",
    "        src=self.dropout((self.tok_embedding(src)*self.scale)+self.pos_embedding(pos))\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            src=layer(src, src_mask)\n",
    "        return src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5582f31-9540-4703-8ebf-7b6c67206c46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee88c2ee-fec1-49cc-bf1c-f6cd4b31b932",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caf476b-3b10-47f4-be4f-a86beb32f785",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
